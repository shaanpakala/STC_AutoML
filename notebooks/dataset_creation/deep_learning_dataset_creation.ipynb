{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6868021",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4f3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch\n",
    "\n",
    "from torch import nn, save, load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f82307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9620831",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/home/spaka002/NSF_REU_2024/\"\n",
    "data_folder = f\"{work_dir}classification_datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fa1b3",
   "metadata": {},
   "source": [
    "# Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b6a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tensor(tensor, save_path):\n",
    "    torch.save(tensor.clone().detach(), save_path)\n",
    "    print(f\"\\nSuccessfully saved tensor to \\n{save_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5115fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_block(clf, opt, loss_fn, X_train, Y_train, num_epochs = 10, batch_size = 128):\n",
    "\n",
    "    train = list()\n",
    "    for i in range(len(X_train)):\n",
    "        train.append((X_train[i], Y_train[i]))\n",
    "\n",
    "    trainloader = DataLoader(train, batch_size)\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "\n",
    "        for batch in trainloader:\n",
    "\n",
    "            x,y = batch \n",
    "            Yhat = clf(x)\n",
    "\n",
    "            loss = loss_fn(Yhat, y)\n",
    "\n",
    "            #backpropogation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()    \n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3278e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_eval(model, x, y, n_splits, opt, loss_fn, num_epochs=10, batch_size=128, smote_train=False):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle = True, random_state = 18)\n",
    "    kf.get_n_splits(x)\n",
    "\n",
    "    overall_metric = 0\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "\n",
    "        Y_train = y[train_index]\n",
    "        Y_test = y[test_index]\n",
    "\n",
    "        if (smote_train):\n",
    "            smote = SMOTE(random_state=18)\n",
    "            X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "        model = train_block(clf = model,\n",
    "                            opt = opt,\n",
    "                            loss_fn = loss_fn, \n",
    "                            X_train = X_train,\n",
    "                            Y_train = Y_train, \n",
    "                            num_epochs = num_epochs,\n",
    "                            batch_size = batch_size)\n",
    "        \n",
    "        \n",
    "        preds = model(X_test).cpu().detach().numpy()\n",
    "        \n",
    "        pred_labels = torch.tensor([x.argmax() for x in preds], dtype = torch.long)\n",
    "        \n",
    "        # _______ insert evaluation metric ___________________________________\n",
    "        \n",
    "        if (len(set(y)) == 2): average = 'binary'\n",
    "        else: average = 'weighted'\n",
    "            \n",
    "        metric_value = f1_score(Y_test.cpu(), pred_labels.cpu(), average = average)\n",
    "        \n",
    "        # ____________________________________________________________________\n",
    "        \n",
    "        overall_metric += metric_value\n",
    "            \n",
    "    return (overall_metric/n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da7210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(df):\n",
    "\n",
    "    num_c = len(list(df.columns))\n",
    "    \n",
    "    for c in range(num_c):\n",
    "        \n",
    "        if (type(data.iloc[:, c][0]) != str): continue\n",
    "\n",
    "        vals = list(set(df.iloc[:, c]))\n",
    "\n",
    "        t_d = dict()\n",
    "\n",
    "        for v in range(len(vals)):\n",
    "            val = vals[v]\n",
    "            t_d[val] = v\n",
    "\n",
    "        df.iloc[:, c] = df.iloc[:, c].map(lambda x: t_d[x])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfe375",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc73df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(f\"{data_folder}car.data\", names = [f\"Feature_{i}\" for i in range(1, 7)] + ['Target'])\n",
    "# data = np.array(convert_categorical(data), dtype = np.int8)\n",
    "\n",
    "# X = torch.tensor(data[:, :-1], dtype = torch.float32)\n",
    "# Y = torch.tensor(data[:, -1], dtype = torch.long)\n",
    "\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9c992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample_amt = 15000\n",
    "\n",
    "# data = pd.read_excel(f\"{data_folder}default_creditcard.xls\")\n",
    "# data = data.iloc[1:, 1:]\n",
    "\n",
    "# indices = list(data[data['Y'] == 0].index)\n",
    "# random.Random(18).shuffle(indices)\n",
    "\n",
    "# negatives = np.array(data.iloc[indices[:undersample_amt]])\n",
    "# positives = np.array(data[data['Y'] == 1])\n",
    "\n",
    "# dataset = np.concatenate((positives, negatives), axis = 0)\n",
    "# data_names = list(data.columns)\n",
    "\n",
    "# del data, negatives, positives\n",
    "\n",
    "# X = np.array(dataset[:, :-1], dtype = np.float32)\n",
    "# Y = np.array(dataset[:, -1], dtype = np.uint8)\n",
    "\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aed59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"{data_folder}MiniBoone_Particle_ID.npy\")\n",
    "\n",
    "X = data[:, :-1]\n",
    "Y = data[:, -1]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1318cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample_amt = 35346\n",
    "\n",
    "# data = pd.read_csv(f\"{data_folder}diabetes_binary.csv\")\n",
    "\n",
    "# negative_indices = list(data[data['Diabetes_binary'] == 0].index)\n",
    "# random.Random(18).shuffle(negative_indices)\n",
    "\n",
    "# negatives = np.array(data.iloc[negative_indices[:undersample_amt]])\n",
    "# positives = np.array(data[data['Diabetes_binary'] == 1])\n",
    "\n",
    "# dataset = np.concatenate((positives, negatives), axis = 0)\n",
    "# data_names = list(data.columns)\n",
    "\n",
    "# del data, negatives, positives, negative_indices\n",
    "\n",
    "# X = np.array(dataset[:, 1:])\n",
    "# Y = np.array(dataset[:, 0])\n",
    "\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c898c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y)\n",
    "plt.title(\"Number of Samples per Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d7f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (130064, 50); Y Shape: (130064,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}; Y Shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b042942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(x, y, portion=1, random_state=18):\n",
    "    \n",
    "    if (portion>=1): return x, y\n",
    "    \n",
    "    X, tx, Y, ty = train_test_split(x, y, test_size=(1-portion), random_state=random_state)\n",
    "    del tx, ty\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa25ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_subset(X, Y, \n",
    "                  portion=0.1, \n",
    "                  random_state=18)\n",
    "\n",
    "X, Y = torch.tensor(X, dtype = torch.float32).to(device), torch.tensor(Y, dtype = torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eaaa53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: torch.Size([13006, 50]); Y Shape: torch.Size([13006])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}; Y Shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee964ea0",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea2211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_clf(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 100, num_fc = 2, act = 'relu', dropout_p = 0.1, num_classes = 2):\n",
    "        super(NN_clf, self).__init__()\n",
    "        \n",
    "        self.num_fc = num_fc\n",
    "\n",
    "        self.in_ = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        if (act == 'relu'):\n",
    "            self.act = nn.ReLU()\n",
    "            \n",
    "        elif (act == 'tanh'):\n",
    "            self.act = nn.Tanh()\n",
    "            \n",
    "        elif (act == 'sigmoid'):\n",
    "            self.act = nn.Sigmoid()\n",
    "        \n",
    "        self.out_ = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.in_(x)\n",
    "        \n",
    "        for i in range(self.num_fc):\n",
    "            x = self.fc(x)\n",
    "            x = self.act(x)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.out_(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc56d7c",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad493dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = False\n",
    "\n",
    "if (run_test):\n",
    "    \n",
    "    num_classes = len(set(Y))\n",
    "\n",
    "    classifier = NN_clf(input_dim = int(X.shape[1]),\n",
    "                                    hidden_dim = 100,                  # can change hidden_dim\n",
    "                                    num_fc = 5,                        # can change number of layers\n",
    "                                    act = 'relu',                      # can change activation function\n",
    "                                    dropout_p = 0.0,                   # can change dropout probability\n",
    "                                    num_classes = num_classes\n",
    "                                   ).to(device)\n",
    "\n",
    "    opt = Adam(classifier.parameters(), lr=5e-3)                    # can change optimizer\n",
    "                                                                    # can change learning rate\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()                                 # can change loss function\n",
    "\n",
    "    result = return_eval(model = classifier, \n",
    "                         x = X, \n",
    "                         y = Y, \n",
    "                         n_splits = 3, \n",
    "                         opt = opt, \n",
    "                         loss_fn = loss_fn, \n",
    "                         num_epochs=25,                   # can change num_epochs\n",
    "                         batch_size=128,                  # can change batch_size\n",
    "                         smote_train=False)               # can change SMOTE\n",
    "\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f555299",
   "metadata": {},
   "source": [
    "# Generate Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a84bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1x8x10x6x4) tensor output.\n",
      "\n",
      " 1920 total combinations.\n"
     ]
    }
   ],
   "source": [
    "dim5=['relu']\n",
    "dim4=list(range(1, 15+1, 2))\n",
    "dim3=list(range(5, 50+1, 5))\n",
    "dim2=[10, 25, 50, 100, 250, 500]\n",
    "dim1=[128, 256, 512, 1024]\n",
    "\n",
    "total_cells = len(dim1)*len(dim2)*len(dim3)*len(dim4)*len(dim5)\n",
    "\n",
    "print(f\"({len(dim5)}x{len(dim4)}x{len(dim3)}x{len(dim2)}x{len(dim1)}) tensor output.\\n\")\n",
    "print(f\" {total_cells} total combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5cdca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1920 combinations done.\n",
      "2/1920 combinations done.\n",
      "3/1920 combinations done.\n",
      "4/1920 combinations done.\n",
      "5/1920 combinations done.\n",
      "6/1920 combinations done.\n",
      "7/1920 combinations done.\n",
      "8/1920 combinations done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-68d57c137596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m                   \u001b[0;31m# can change num_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m                   \u001b[0;31m# can change batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                         smote_train=False)                       # can change SMOTE\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d0ae4ca66267>\u001b[0m in \u001b[0;36mreturn_eval\u001b[0;34m(model, x, y, n_splits, opt, loss_fn, num_epochs, batch_size, smote_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m                             \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                             \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                             batch_size = batch_size)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2234b1f8b179>\u001b[0m in \u001b[0;36mtrain_block\u001b[0;34m(clf, opt, loss_fn, X_train, Y_train, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#backpropogation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "num_classes = len(set(Y))\n",
    "\n",
    "tensor_5 = list()\n",
    "for act in dim5:\n",
    "\n",
    "    tensor_4 = list()\n",
    "    for num_fc in dim4:\n",
    "\n",
    "        tensor_3 = list()\n",
    "        for num_epochs in dim3:\n",
    "\n",
    "            tensor_2 = list()\n",
    "            for hidden_dim in dim2:\n",
    "\n",
    "                tensor_1 = list()\n",
    "                for batch_size in dim1:\n",
    "\n",
    "                    classifier = NN_clf(input_dim = int(X.shape[1]),\n",
    "                                        hidden_dim = hidden_dim,                  # can change hidden_dim\n",
    "                                        num_fc = num_fc,                          # can change number of layers\n",
    "                                        act = act,                                # can change activation function\n",
    "                                        dropout_p=0.0,\n",
    "                                        num_classes = num_classes\n",
    "                                    ).to(device)\n",
    "\n",
    "                    opt = Adam(classifier.parameters(), lr=5e-3)                  # can change optimizer & learning rate\n",
    "\n",
    "                    loss_fn = nn.CrossEntropyLoss()                               # can change loss function\n",
    "\n",
    "                    result = return_eval(model = classifier, \n",
    "                                        x = X, \n",
    "                                        y = Y, \n",
    "                                        n_splits = 3, \n",
    "                                        opt = opt, \n",
    "                                        loss_fn = loss_fn, \n",
    "                                        num_epochs=num_epochs,                   # can change num_epochs\n",
    "                                        batch_size=batch_size,                   # can change batch_size\n",
    "                                        smote_train=False)                       # can change SMOTE\n",
    "\n",
    "                    i+=1\n",
    "                    if (i%1==0): print(f\"{i}/{total_cells} combinations done.\")\n",
    "\n",
    "                    tensor_1+= [result]\n",
    "\n",
    "                tensor_2+= [tensor_1]\n",
    "\n",
    "            tensor_3+= [tensor_2]\n",
    "\n",
    "        tensor_4+= [tensor_3]\n",
    "\n",
    "    print(f\"\\n{len(tensor_5)}/{len(dim5)} 4th order tensors done.\\n\")\n",
    "\n",
    "tensor = torch.tensor(tensor_5).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(tensor_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 8, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fa3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0042, 0.0000, 0.0000, 0.0000, 0.0000, 0.0212],\n",
      "          [0.0218, 0.0077, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0670, 0.0022, 0.0000, 0.2633, 0.0206, 0.0861],\n",
      "          ...,\n",
      "          [0.5777, 0.6279, 0.5995, 0.6182, 0.6328, 0.5852],\n",
      "          [0.6226, 0.6284, 0.6150, 0.6272, 0.6145, 0.6030],\n",
      "          [0.4138, 0.5716, 0.5896, 0.5088, 0.4477, 0.4493]],\n",
      "\n",
      "         [[0.0659, 0.0000, 0.0000, 0.0136, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0226, 0.1479, 0.1452, 0.0876, 0.0000],\n",
      "          [0.4656, 0.4313, 0.1711, 0.1166, 0.0333, 0.2443],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.6148, 0.5896, 0.5896, 0.5896],\n",
      "          [0.6320, 0.5875, 0.6488, 0.6457, 0.6121, 0.6007],\n",
      "          [0.5896, 0.5720, 0.6084, 0.5657, 0.5777, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.2764, 0.0000, 0.0000, 0.0066, 0.2294],\n",
      "          [0.1031, 0.0000, 0.0000, 0.0000, 0.0226, 0.0564],\n",
      "          [0.2303, 0.4263, 0.5049, 0.3778, 0.4941, 0.3371],\n",
      "          ...,\n",
      "          [0.5533, 0.5268, 0.5547, 0.5438, 0.5562, 0.5565],\n",
      "          [0.6737, 0.6235, 0.6963, 0.6916, 0.6185, 0.6470],\n",
      "          [0.5896, 0.5929, 0.5896, 0.5896, 0.5896, 0.5402]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5540, 0.3202, 0.3905, 0.0009, 0.2375, 0.1663],\n",
      "          [0.5268, 0.3558, 0.4634, 0.4463, 0.3558, 0.5672],\n",
      "          [0.5780, 0.3893, 0.4041, 0.3893, 0.5360, 0.5778],\n",
      "          ...,\n",
      "          [0.6776, 0.6829, 0.7063, 0.7178, 0.6392, 0.6322],\n",
      "          [0.6731, 0.6954, 0.6956, 0.6920, 0.7151, 0.6905],\n",
      "          [0.5880, 0.5533, 0.5801, 0.6457, 0.6077, 0.5555]],\n",
      "\n",
      "         [[0.1007, 0.3352, 0.5896, 0.1135, 0.0417, 0.5525],\n",
      "          [0.2530, 0.2830, 0.3413, 0.5896, 0.3552, 0.2464],\n",
      "          [0.5896, 0.5391, 0.5896, 0.5869, 0.5896, 0.6126],\n",
      "          ...,\n",
      "          [0.6924, 0.6776, 0.6924, 0.6852, 0.6494, 0.6798],\n",
      "          [0.7173, 0.7151, 0.7138, 0.6874, 0.7251, 0.7213],\n",
      "          [0.6068, 0.5973, 0.5823, 0.5605, 0.6382, 0.5719]],\n",
      "\n",
      "         [[0.5824, 0.3502, 0.1124, 0.5583, 0.5695, 0.3578],\n",
      "          [0.6037, 0.3672, 0.5716, 0.3574, 0.2701, 0.2501],\n",
      "          [0.5716, 0.3669, 0.5896, 0.5639, 0.6037, 0.5896],\n",
      "          ...,\n",
      "          [0.6658, 0.6921, 0.6556, 0.6927, 0.6863, 0.6831],\n",
      "          [0.7251, 0.7317, 0.7323, 0.6964, 0.7023, 0.7132],\n",
      "          [0.5814, 0.6280, 0.6158, 0.5848, 0.6017, 0.6092]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0381, 0.0000, 0.1044],\n",
      "          ...,\n",
      "          [0.4729, 0.4491, 0.5896, 0.4491, 0.4491, 0.4491],\n",
      "          [0.5989, 0.5896, 0.5910, 0.5896, 0.5896, 0.5896],\n",
      "          [0.4099, 0.3474, 0.5583, 0.5279, 0.5896, 0.4044]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0346, 0.0000, 0.1064, 0.0000],\n",
      "          [0.1013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0934],\n",
      "          [0.3594, 0.1094, 0.0911, 0.0838, 0.2921, 0.1140],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5840],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.3669]],\n",
      "\n",
      "         [[0.0000, 0.0038, 0.0000, 0.0000, 0.0000, 0.0907],\n",
      "          [0.1418, 0.1251, 0.0000, 0.0008, 0.1829, 0.1013],\n",
      "          [0.0866, 0.3656, 0.3558, 0.5896, 0.2506, 0.2856],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.3669, 0.3669, 0.5896],\n",
      "          [0.6024, 0.4144, 0.5997, 0.6047, 0.6148, 0.6148],\n",
      "          [0.5896, 0.5896, 0.5295, 0.6316, 0.5896, 0.5896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0423, 0.1483, 0.0008, 0.0010, 0.3479],\n",
      "          [0.3558, 0.1717, 0.1457, 0.5896, 0.1050, 0.3558],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5839],\n",
      "          ...,\n",
      "          [0.6814, 0.6767, 0.6625, 0.6613, 0.6850, 0.6709],\n",
      "          [0.7148, 0.7020, 0.7301, 0.7134, 0.6996, 0.7346],\n",
      "          [0.6148, 0.6026, 0.6437, 0.6359, 0.6068, 0.6359]],\n",
      "\n",
      "         [[0.0000, 0.1631, 0.0008, 0.0000, 0.0000, 0.5896],\n",
      "          [0.1829, 0.3558, 0.3587, 0.3558, 0.2000, 0.5512],\n",
      "          [0.5896, 0.3669, 0.5839, 0.5557, 0.5896, 0.4633],\n",
      "          ...,\n",
      "          [0.6986, 0.6777, 0.6777, 0.6481, 0.6694, 0.6821],\n",
      "          [0.7320, 0.7235, 0.7341, 0.7266, 0.7326, 0.7301],\n",
      "          [0.6150, 0.6330, 0.6185, 0.6436, 0.6174, 0.5974]],\n",
      "\n",
      "         [[0.2417, 0.3558, 0.3558, 0.1829, 0.1124, 0.5896],\n",
      "          [0.3558, 0.3634, 0.5555, 0.2530, 0.3579, 0.2174],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          ...,\n",
      "          [0.6888, 0.6520, 0.6716, 0.6721, 0.6720, 0.6966],\n",
      "          [0.7457, 0.7420, 0.7498, 0.7288, 0.7372, 0.7442],\n",
      "          [0.5920, 0.6207, 0.6289, 0.6310, 0.6112, 0.5925]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.5896, 0.0000, 0.1124, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1829, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.4491, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.4168, 0.2333, 0.5896, 0.3558]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.1124, 0.0000],\n",
      "          [0.1124, 0.0000, 0.0000, 0.0000, 0.0085, 0.0000],\n",
      "          [0.1566, 0.1124, 0.2431, 0.1829, 0.0000, 0.1829],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.3669, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.4491, 0.3669, 0.5716, 0.5896, 0.4447]],\n",
      "\n",
      "         [[0.0000, 0.1696, 0.5896, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5896, 0.1829, 0.3558, 0.3558, 0.1829, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.3669, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.3669, 0.5839, 0.5896, 0.5896],\n",
      "          [0.4757, 0.4757, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.1829, 0.0009, 0.1829, 0.3558, 0.0008],\n",
      "          [0.1829, 0.1829, 0.0423, 0.2533, 0.1013, 0.0423],\n",
      "          [0.5896, 0.3705, 0.6037, 0.5896, 0.3588, 0.5896],\n",
      "          ...,\n",
      "          [0.6680, 0.6358, 0.6374, 0.6193, 0.6701, 0.6328],\n",
      "          [0.6367, 0.6635, 0.6377, 0.6302, 0.6555, 0.6886],\n",
      "          [0.5989, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.3558, 0.0662, 0.3443, 0.1863, 0.3558, 0.1429],\n",
      "          [0.3669, 0.3558, 0.3669, 0.5896, 0.3558, 0.2403],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          ...,\n",
      "          [0.6614, 0.6521, 0.6134, 0.6767, 0.6653, 0.6577],\n",
      "          [0.7346, 0.7132, 0.7225, 0.6934, 0.7025, 0.6831],\n",
      "          [0.5896, 0.6174, 0.5896, 0.6148, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.3558, 0.1829, 0.3558, 0.1829, 0.1829, 0.0000],\n",
      "          [0.3558, 0.0423, 0.2358, 0.3558, 0.0008, 0.0008],\n",
      "          [0.5896, 0.5896, 0.3669, 0.3669, 0.3669, 0.5896],\n",
      "          ...,\n",
      "          [0.6481, 0.6194, 0.6254, 0.6983, 0.6566, 0.6686],\n",
      "          [0.6672, 0.7216, 0.7053, 0.7421, 0.6887, 0.6759],\n",
      "          [0.6379, 0.5896, 0.6265, 0.5896, 0.6148, 0.6174]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1829, 0.0000],\n",
      "          ...,\n",
      "          [0.5896, 0.2530, 0.4491, 0.5896, 0.5896, 0.5896],\n",
      "          [0.4757, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.3587, 0.1829, 0.1829, 0.5896, 0.3558, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0423, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3558, 0.0000, 0.5896, 0.0000, 0.1124, 0.0000],\n",
      "          [0.0000, 0.5896, 0.0000, 0.1013, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.4757, 0.5896, 0.5896, 0.3669],\n",
      "          [0.3669, 0.5896, 0.5896, 0.5896, 0.3669, 0.5896],\n",
      "          [0.4491, 0.4491, 0.3558, 0.2152, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0423],\n",
      "          [0.0000, 0.3057, 0.0000, 0.0423, 0.0000, 0.0000],\n",
      "          [0.1124, 0.3558, 0.5896, 0.0000, 0.1013, 0.1829],\n",
      "          ...,\n",
      "          [0.3669, 0.3669, 0.3669, 0.3669, 0.3669, 0.5896],\n",
      "          [0.4290, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5402, 0.6489, 0.5896, 0.3669, 0.3669, 0.4991]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1829, 0.0008, 0.0000, 0.1829, 0.0423, 0.0411],\n",
      "          [0.3669, 0.1829, 0.1124, 0.3558, 0.0423, 0.3558],\n",
      "          [0.5896, 0.5896, 0.2448, 0.5896, 0.3669, 0.3558],\n",
      "          ...,\n",
      "          [0.6148, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5994, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.1829, 0.1829, 0.0423, 0.0423, 0.1829],\n",
      "          [0.5896, 0.3558, 0.1829, 0.5896, 0.3558, 0.1124],\n",
      "          [0.3669, 0.5896, 0.5896, 0.3558, 0.3669, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.6268, 0.6701, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.6148, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.1829, 0.3558, 0.0000, 0.0008, 0.1013, 0.3558],\n",
      "          [0.5896, 0.1124, 0.0008, 0.2860, 0.3558, 0.0423],\n",
      "          [0.5896, 0.5896, 0.5716, 0.5896, 0.5896, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.6359, 0.5896, 0.6148, 0.5896, 0.6359],\n",
      "          [0.5896, 0.5896, 0.6142, 0.5896, 0.6541, 0.6262],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.5896, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0038, 0.0000, 0.0000, 0.1829, 0.1829, 0.0000],\n",
      "          ...,\n",
      "          [0.3669, 0.2264, 0.4491, 0.4491, 0.5896, 0.3587],\n",
      "          [0.5896, 0.3351, 0.4757, 0.5896, 0.3351, 0.4637],\n",
      "          [0.3587, 0.3558, 0.3558, 0.3558, 0.3558, 0.1829]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1829, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5896, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0423, 0.1124, 0.3558, 0.0000, 0.3558, 0.0000],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.4757, 0.3669, 0.5896, 0.5896],\n",
      "          [0.3669, 0.5896, 0.3669, 0.3669, 0.5896, 0.2530],\n",
      "          [0.5896, 0.3558, 0.2530, 0.3669, 0.2152, 0.3669]],\n",
      "\n",
      "         [[0.1013, 0.1124, 0.1013, 0.0000, 0.5896, 0.0008],\n",
      "          [0.0008, 0.0000, 0.1829, 0.0423, 0.0000, 0.3558],\n",
      "          [0.0008, 0.1013, 0.0879, 0.2530, 0.3558, 0.0423],\n",
      "          ...,\n",
      "          [0.3669, 0.5896, 0.3669, 0.5896, 0.5896, 0.3669],\n",
      "          [0.3669, 0.3669, 0.3669, 0.3669, 0.3669, 0.3669],\n",
      "          [0.2530, 0.5896, 0.5896, 0.2530, 0.5896, 0.5896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0008, 0.1124, 0.0000, 0.5896, 0.1829, 0.0008],\n",
      "          [0.1829, 0.5896, 0.0000, 0.3558, 0.2418, 0.1124],\n",
      "          [0.5896, 0.5896, 0.2530, 0.5896, 0.3669, 0.3587],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.6037, 0.5896, 0.3669, 0.5896, 0.3669, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.2418, 0.0008, 0.1013, 0.0190],\n",
      "          [0.0038, 0.0000, 0.3558, 0.3558, 0.0423, 0.5896],\n",
      "          [0.3669, 0.5896, 0.5896, 0.5896, 0.3669, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.6359, 0.5896, 0.5896, 0.5896, 0.6359],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.1829, 0.0423, 0.1124, 0.1124, 0.0008],\n",
      "          [0.3558, 0.1013, 0.2418, 0.5896, 0.5896, 0.0008],\n",
      "          [0.3558, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.6354, 0.5896, 0.5896, 0.6541, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.6338, 0.5896]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1013, 0.0000, 0.0000, 0.0000, 0.1124, 0.0000],\n",
      "          [0.0000, 0.1829, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5896, 0.3587, 0.3587, 0.4491, 0.4491, 0.4491],\n",
      "          [0.4757, 0.5896, 0.4757, 0.5896, 0.4757, 0.5896],\n",
      "          [0.5896, 0.3558, 0.3558, 0.3558, 0.3558, 0.5896]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5896],\n",
      "          [0.0423, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1013, 0.0000, 0.0008, 0.0000, 0.0000, 0.3587],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.4757, 0.5896, 0.5896],\n",
      "          [0.5896, 0.3669, 0.5896, 0.3669, 0.3669, 0.5896],\n",
      "          [0.3558, 0.5896, 0.5896, 0.3587, 0.4491, 0.3558]],\n",
      "\n",
      "         [[0.0008, 0.0008, 0.0000, 0.0423, 0.1124, 0.0000],\n",
      "          [0.0038, 0.0000, 0.0008, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3558, 0.1829, 0.1829, 0.0453, 0.2530, 0.0000],\n",
      "          ...,\n",
      "          [0.3669, 0.5896, 0.5896, 0.5896, 0.3669, 0.5896],\n",
      "          [0.3669, 0.5896, 0.5896, 0.3669, 0.3669, 0.3669],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.4757, 0.5896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0008, 0.5896, 0.5896, 0.1829, 0.1124, 0.1013],\n",
      "          [0.3558, 0.3558, 0.1013, 0.1013, 0.5896, 0.3558],\n",
      "          [0.3669, 0.5896, 0.5896, 0.5896, 0.3669, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.6635, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.1124, 0.0008, 0.5896, 0.5896, 0.0000, 0.0000],\n",
      "          [0.3558, 0.2418, 0.2530, 0.2418, 0.3558, 0.3558],\n",
      "          [0.3669, 0.5896, 0.3669, 0.3587, 0.5896, 0.3558],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.6359],\n",
      "          [0.5896, 0.6265, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896]],\n",
      "\n",
      "         [[0.1829, 0.3669, 0.3558, 0.2152, 0.0008, 0.0000],\n",
      "          [0.3558, 0.3587, 0.3558, 0.3558, 0.3558, 0.1858],\n",
      "          [0.5896, 0.3893, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          ...,\n",
      "          [0.5896, 0.5896, 0.6870, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.5896, 0.5896],\n",
      "          [0.5896, 0.5896, 0.5896, 0.5896, 0.6541, 0.5896]]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(np.round(tensor, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved tensor to \n",
      "/home/spaka002/NSF_REU_2024/meta_datasets/FCNN_car_evaluation_719.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (False):\n",
    "    save_tensor(tensor,\n",
    "                save_path = f\"{work_dir}meta_datasets/FCNN_car_evaluation_719.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
