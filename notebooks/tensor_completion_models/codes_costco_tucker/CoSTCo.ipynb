{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6caed7e-a050-4d62-9d4a-3a7a3d3965f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "import numpy as np\n",
    "from dotmap import DotMap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Tensor decomposition\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "from costco import *\n",
    "from read import *\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8badfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526fa4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760 total cells in tensor.\n",
      "288 non-zero cells.\n"
     ]
    }
   ],
   "source": [
    "work_dir = \"/Users/shaanpakala/Desktop/NSF_REU_2024/Research/\"\n",
    "data_folder = f\"{work_dir}classification_datasets/\"\n",
    "\n",
    "t1 = torch.load(f\"{work_dir}meta_datasets/FCNN_glass_717.pt\")\n",
    "t2 = torch.load(f\"{work_dir}meta_datasets/FCNN_car_evaluation_717.pt\")\n",
    "\n",
    "original_tensor = torch.stack((t1, t2))\n",
    "t = original_tensor.clone()\n",
    "\n",
    "del t1, t2\n",
    "\n",
    "rand_index = lambda x: tuple([int(random.random()*i) for i in x])\n",
    "\n",
    "def get_indices(shape, num_indices):\n",
    "    \n",
    "    index_bank = dict()\n",
    "    \n",
    "    while (len(index_bank) < num_indices):\n",
    "        index_bank[rand_index(shape)] = True\n",
    "        \n",
    "    return list(index_bank)\n",
    "\n",
    "total_cells = 1\n",
    "for s in t.shape: total_cells*=s\n",
    "\n",
    "print(f\"{total_cells} total cells in tensor.\")\n",
    "\n",
    "portion_of_entries = 0.05\n",
    "indices = get_indices(t.shape, int(total_cells*(1-portion_of_entries)))\n",
    "for index in indices: t[index] = 0\n",
    "    \n",
    "print(f\"{int(total_cells*(portion_of_entries))} non-zero cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dbc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = t.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0583124",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = sparse_tensor.indices().t().to(device) # NNZ x mode\n",
    "values = sparse_tensor.values().to(device) # NNZ\n",
    "values = values.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74acd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_size = sparse_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76d92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6a870",
   "metadata": {},
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4755cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class COODataset(Dataset):\n",
    "    def __init__(self, idxs, vals):\n",
    "        self.idxs = idxs\n",
    "        self.vals = vals\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vals.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.idxs[idx], self.vals[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961f95d2-8b41-41fc-88ea-d12b10568e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "dataset = COODataset(indices, values)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d96f2",
   "metadata": {},
   "source": [
    "# 2. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360eda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoSTCo(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CoSTCo, self).__init__()\n",
    "        nc = cfg.nc\n",
    "        self.rank = cfg.rank\n",
    "        self.sizes = cfg.sizes\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(self.sizes[i], self.rank)\n",
    "                                     for i in range(len(self.sizes))])\n",
    "        self.conv1 = nn.Conv2d(1, nc, kernel_size=(1, len(self.sizes)), padding=0)\n",
    "        self.conv2 = nn.Conv2d(nc, nc, kernel_size=(self.rank, 1), padding=0)\n",
    "        self.fc1 = nn.Linear(nc, nc)\n",
    "        self.fc2 = nn.Linear(nc, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self):\n",
    "        \n",
    "        for i in range(len(self.embeds)):\n",
    "            nn.init.kaiming_uniform_(self.embeds[i].weight.data)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: indices of nnz\n",
    "        '''\n",
    "        \n",
    "        embeds = [self.embeds[m](inputs[:, m]).reshape(-1, self.rank, 1)\n",
    "                  for m in range(len(self.sizes))]\n",
    "        x = torch.cat(embeds, dim=2)\n",
    "        x = x.reshape(-1, 1, self.rank, len(self.sizes))# NNZ_batch x 1 x rank x nmode \n",
    "        \n",
    "        # CNN on stacked embeds\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Aggregate with mlps\n",
    "        x = x.view(-1, x.size(1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91564cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.loss = 'bceloss'\n",
    "# cfg.rank = 8\n",
    "# cfg.nc = 16\n",
    "# cfg.lr = 1e-3\n",
    "# cfg.wd = 1e-5\n",
    "# cfg.epochs = 100\n",
    "# batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63403737",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = DotMap()\n",
    "cfg.nc = 8\n",
    "cfg.rank = 3\n",
    "cfg.sizes = tensor_size\n",
    "cfg.lr = 0.0001\n",
    "cfg.wd = 0.0001\n",
    "cfg.epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b1950e-b219-4763-9db6-bad66bb958b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = CoSTCo(cfg).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b9e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Train RMSE: 0.4626\t\n",
      "Epoch 200 Train RMSE: 0.4154\t\n",
      "Epoch 300 Train RMSE: 0.3720\t\n",
      "Epoch 400 Train RMSE: 0.3308\t\n",
      "Epoch 500 Train RMSE: 0.2924\t\n",
      "Epoch 600 Train RMSE: 0.2608\t\n",
      "Epoch 700 Train RMSE: 0.2387\t\n",
      "Epoch 800 Train RMSE: 0.2260\t\n",
      "Epoch 900 Train RMSE: 0.2196\t\n",
      "Epoch 1000 Train RMSE: 0.2160\t\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "err_lst = []\n",
    "old_rmse = 1e+6\n",
    "# train the model\n",
    "for epoch in range(cfg.epochs):\n",
    "\n",
    "    model.train()\n",
    "#     epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = batch[0], batch[1]\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.to(torch.double), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # epoch_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            train_rec = model(indices)\n",
    "            train_rmse = rmse(train_rec, values)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} Train RMSE: {train_rmse:.4f}\\t\")\n",
    "\n",
    "            if (old_rmse <= train_rmse):\n",
    "                flag +=1\n",
    "            if flag == 10:\n",
    "                break\n",
    "            old_rmse = train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8cb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(all_indices, train_indices):\n",
    "\n",
    "    unique_dict = dict()\n",
    "\n",
    "    for i in [tuple([int(y) for y in x]) for x in all_indices]:\n",
    "        unique_dict[i] = True\n",
    "\n",
    "    for j in [tuple([int(y) for y in x]) for x in train_indices]:\n",
    "        del unique_dict[j]\n",
    "\n",
    "    unique_indices = torch.tensor([list(x) for x in list(unique_dict)])\n",
    "\n",
    "    del unique_dict\n",
    "    \n",
    "    return unique_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e18e5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_MAE(tensor_completion_model, full_t, sparse_t):\n",
    "    \n",
    "    unique_indices = get_unique(full_t.to_sparse().indices().t(), sparse_t.indices().t())\n",
    "    unique_recon = model(unique_indices)\n",
    "\n",
    "    unique_recon_MAE = 0\n",
    "    for i in range(len(unique_indices)):\n",
    "        unique_index = tuple(unique_indices[i])\n",
    "        unique_value = unique_recon[i]\n",
    "\n",
    "        unique_recon_MAE += float(abs(unique_value - original_tensor[unique_index]))\n",
    "\n",
    "    unique_recon_MAE /= len(unique_indices)\n",
    "    \n",
    "    return unique_recon_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddc3eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = get_unique(original_tensor.to_sparse().indices().t(), sparse_tensor.indices().t())\n",
    "unique_recon = model(unique_indices)\n",
    "\n",
    "unique_recon_MAE = 0\n",
    "for i in range(len(unique_indices)):\n",
    "    unique_index = tuple(unique_indices[i])\n",
    "    unique_value = unique_recon[i]\n",
    "\n",
    "    unique_recon_MAE += float(abs(unique_value - original_tensor[unique_index]))\n",
    "\n",
    "unique_recon_MAE /= len(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4801f608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19085306875266042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_MAE(tensor_completion_model = model,\n",
    "               full_t = original_tensor,\n",
    "               sparse_t = sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81310c1-82c9-42b4-b699-7a391a017840",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \n\u001b[0;32m----> 2\u001b[0m     test_rec \u001b[38;5;241m=\u001b[39m  model(test_indices)\n\u001b[1;32m      3\u001b[0m     test_rmse \u001b[38;5;241m=\u001b[39m rmse(test_values)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestRMSE:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_indices' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    test_rec =  model(test_indices)\n",
    "    test_rmse = rmse(test_values)\n",
    "\n",
    "    print(f\"TestRMSE:{test_rmse:.4f}\")\n",
    "    #     wandb.log({\"test_rmse\":dct.test_rmse, \"acc\":dct.acc, \"recall\": dct.recall,\n",
    "    #                \"prec\": dct.prec, \"f1\":dct.f1, \"auc\":dct.auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = f\"{name}_rank{cfg.rank} lr{cfg.lr} wd{cfg.wd} nc:{cfg.nc}\"\n",
    "exp_title = f\"{name} || r:{cfg.rank} lr:{cfg.lr} nc:{cfg.nc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cccd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 3), dpi = 200)\n",
    "plt.plot(np.vstack(err_lst)[:, 0])\n",
    "plt.plot(np.vstack(err_lst)[:, 1])\n",
    "plt.title(f\"{exp_title} \\n TestRMSE:{test_rmse:.4f} Acc:{r['acc']:.4f} AUC : {r['auc']:.4f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f'training_results/{exp_name}_costco_training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7742c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "factors = [model.embeds[i].weight.data.cpu().numpy() for i in range(3)]\n",
    "plt.figure(figsize=(13, 4), dpi = 300)\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(1, 3, i)\n",
    "    fmat = factors[i-1]\n",
    "    sns.heatmap(fmat.T @ fmat, cmap='vlag')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Rank')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'training_results/{exp_name}_costco_factors_corr.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 4))\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(1, 3, i)\n",
    "    fmat = factors[i-1]\n",
    "    sns.heatmap(fmat)\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Dimensionality')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'training_results/{exp_name}_costco_factors_corr.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cadbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
