{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utilities.sklearn_grid_search import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device to run this on\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data\n",
    "\n",
    "n_samples, n_features = 1000, 10                      # number of samples & number of features\n",
    "\n",
    "x = torch.randn(n_samples, n_features)                # randomly generated features\n",
    "weights = torch.randn(n_features) * 5                 # randomly generated weights\n",
    "\n",
    "y = (x @ weights)                                     # linear combinations of random features & weights\n",
    "y += torch.randn(n_samples) * abs(y).mean() * 0.5     # normal random error\n",
    "\n",
    "y = nn.Sigmoid()(y).round()                           # sigmoid for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model\n",
    "model = RandomForestClassifier(random_state = 18)\n",
    "\n",
    "# input dictionary corresponding to parameters & ranges to test\n",
    "param_dict = {\n",
    "  \n",
    "              'max_depth':[2, 3, 4, 5, 6, 10, 12, 16, None],\n",
    "              'max_features': ['sqrt', 'log2', 2, 3, 5, 7, 9, 12, None],\n",
    "              'n_estimators': [5, 10, 25, 50, 100, 150, 200, 300],\n",
    "\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/648 total combinations in sparse tensor.\n",
      "1/25 param_combinations done.\n",
      "2/25 param_combinations done.\n",
      "3/25 param_combinations done.\n",
      "4/25 param_combinations done.\n",
      "5/25 param_combinations done.\n",
      "6/25 param_combinations done.\n",
      "7/25 param_combinations done.\n",
      "8/25 param_combinations done.\n",
      "9/25 param_combinations done.\n",
      "10/25 param_combinations done.\n",
      "11/25 param_combinations done.\n",
      "12/25 param_combinations done.\n",
      "13/25 param_combinations done.\n",
      "14/25 param_combinations done.\n",
      "15/25 param_combinations done.\n",
      "16/25 param_combinations done.\n",
      "17/25 param_combinations done.\n",
      "18/25 param_combinations done.\n",
      "19/25 param_combinations done.\n",
      "20/25 param_combinations done.\n",
      "21/25 param_combinations done.\n",
      "22/25 param_combinations done.\n",
      "23/25 param_combinations done.\n",
      "24/25 param_combinations done.\n",
      "25/25 param_combinations done.\n",
      "\n",
      "Running sparse tensor completion...\n",
      "Done with sparse tensor completion!\n",
      "\n",
      "Evaluating predicted best parameters.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# run function to approximate best parameter combinations using Sparse Tensor Completion\n",
    "\n",
    "best_estimated_params= return_best_k_params(model = model,                              # ML model to hyperparameter tune\n",
    "                                            param_dict = param_dict,                    # dictionary of parameters\n",
    "                                            X = x,\n",
    "                                            Y = y,\n",
    "                                            num_top_combinations = 10,                  # number of best estimated combinations to return\n",
    "                                            cv_splits = 5,                              # number of Cross Validation folds\n",
    "                                            tensor_training_portion = 25,               # fraction/number of combinations computed to estimate all\n",
    "                                            tensor_completion_model = 'cpd.smooth',     # sparse tensor completion model\n",
    "                                            metric = 'f1',                              # evaluation metric\n",
    "                                            rank = 5,                                   # rank decomposition used for tensor completion\n",
    "                                            device = device,                            # device to run this on\n",
    "                                            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 12, 'max_features': 5, 'n_estimators': 200} \n",
      "actual eval = 0.81595\n",
      "\n",
      "{'max_depth': 6, 'max_features': 3, 'n_estimators': 25} \n",
      "actual eval = 0.80705\n",
      "\n",
      "{'max_depth': 6, 'max_features': 5, 'n_estimators': 25} \n",
      "actual eval = 0.80387\n",
      "\n",
      "{'max_depth': 6, 'max_features': 5, 'n_estimators': 10} \n",
      "actual eval = 0.80096\n",
      "\n",
      "{'max_depth': 3, 'max_features': 3, 'n_estimators': 25} \n",
      "actual eval = 0.79592\n",
      "\n",
      "{'max_depth': 3, 'max_features': 5, 'n_estimators': 25} \n",
      "actual eval = 0.78195\n",
      "\n",
      "{'max_depth': 6, 'max_features': 3, 'n_estimators': 10} \n",
      "actual eval = 0.77302\n",
      "\n",
      "{'max_depth': 3, 'max_features': 12, 'n_estimators': 25} \n",
      "actual eval = 0.76612\n",
      "\n",
      "{'max_depth': 3, 'max_features': 12, 'n_estimators': 10} \n",
      "actual eval = 0.76205\n",
      "\n",
      "{'max_depth': 3, 'max_features': 3, 'n_estimators': 10} \n",
      "actual eval = 0.75967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display best estimated parameters and their actual evaluation metric\n",
    "for p in best_estimated_params: print(f\"{p[0]} \\nactual eval = {p[1]:.5f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
